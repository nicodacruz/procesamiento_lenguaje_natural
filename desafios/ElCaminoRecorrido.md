# DesafÃ­os de NLP â€“ FIUBA / CEIA

> De contar palabras a traducir oraciones completas, paso a paso en cuatro notebooks.

Este repositorio reÃºne las entregas de los **DesafÃ­os 1, 2, 3 y 4** de la materia  
**Procesamiento de Lenguaje Natural (FIUBA â€“ CEIA)**.  
La idea es mostrar, de forma incremental, cÃ³mo pasamos de enfoques â€œclÃ¡sicosâ€ de NLP  
a modelos neuronales de traducciÃ³n.

---

## ğŸ—‚ Contenido del repositorio

### ğŸ§© DesafÃ­o 1 â€“ Representaciones clÃ¡sicas y clasificaciÃ³n de textos  
`Desafio_1-Rodrigues da Cruz.ipynb`  

- Carga y exploraciÃ³n del dataset de *20 Newsgroups*.  
- VectorizaciÃ³n de textos con **BoW** y **TF-IDF**.  
- Entrenamiento de modelos de clasificaciÃ³n de documentos.  
- AnÃ¡lisis de similitud entre documentos y tÃ©rminos.

---

### ğŸµ DesafÃ­o 2 â€“ Word embeddings sobre letras de canciones  
`Desafio_2_Rodrigues_da_Cruz (1).ipynb`  

- Entrenamiento de un modelo **Word2Vec** sobre letras (ej. Bob Dylan).  
- BÃºsqueda de palabras similares y casos de â€œla que no encajaâ€.  
- ReducciÃ³n de dimensiÃ³n y visualizaciÃ³n del espacio de palabras.  
- InterpretaciÃ³n de grupos semÃ¡nticos en el embedding.

---

### âœï¸ DesafÃ­o 3 â€“ Modelo de lenguaje a nivel caracter  
`Desafio_3_Rodrigues_da_Cruz.ipynb`  

- PreparaciÃ³n de un corpus a nivel caracter para predicciÃ³n del siguiente sÃ­mbolo.  
- ConstrucciÃ³n de un modelo recurrente (Embedding + LSTM).  
- GeneraciÃ³n de texto variando la temperatura para analizar creatividad vs. coherencia.  
- Comentarios sobre el comportamiento del modelo y sus lÃ­mites.

---

### ğŸŒ DesafÃ­o 4 â€“ TraducciÃ³n automÃ¡tica (es â†’ en)  
`Desafio_4_Rodrigues_da_Cruz.ipynb`  

- Uso de un corpus de pares de oraciones espaÃ±olâ€“inglÃ©s (tipo Anki deck).  
- Limpieza, tokenizaciÃ³n y armado de secuencias para encoderâ€“decoder.  
- ImplementaciÃ³n de un modelo de **traducciÃ³n neuronal** (seq2seq).  
- EvaluaciÃ³n cualitativa de traducciones en oraciones no vistas.

---

## âš™ï¸ CÃ³mo ejecutar los notebooks

1. Crear y activar un entorno de Python (3.10+ recomendado).
2. Instalar las dependencias principales (ejemplo):

   ```bash
   pip install scikit-learn gensim nltk torch matplotlib pandas seaborn
