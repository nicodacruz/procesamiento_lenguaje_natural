{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6c - traductor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Traductor\n",
        "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles de Anki de traducciones de texto en diferentes idiomas. Se construirá un modelo traductor seq2seq utilizando encoder-decoder.\\\n",
        "[LINK](https://www.manythings.org/anki/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ],
      "metadata": {
        "id": "FGmtK8J19PNk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYatMIdk_eT",
        "outputId": "a2029a8c-53e7-4712-f645-2153960dd833"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "!pip3 install torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYpIWGaXxfKe",
        "outputId": "1bda33f7-569f-4901-b74c-fde7d5ecf859"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ],
      "metadata": {
        "id": "GHFPS5KNxgR9",
        "outputId": "7748e26e-5bb9-4496-896f-30fd1e4e3d97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-30 23:10:40--  http://torch_helpers.py/\n",
            "Resolving torch_helpers.py (torch_helpers.py)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘torch_helpers.py’\n",
            "--2025-11-30 23:10:40--  https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23883 (23K) [text/plain]\n",
            "Saving to: ‘torch_helpers.py’\n",
            "\n",
            "\rtorch_helpers.py      0%[                    ]       0  --.-KB/s               \rtorch_helpers.py    100%[===================>]  23.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-11-30 23:10:40 (15.9 MB/s) - ‘torch_helpers.py’ saved [23883/23883]\n",
            "\n",
            "FINISHED --2025-11-30 23:10:40--\n",
            "Total wall clock time: 0.3s\n",
            "Downloaded: 1 files, 23K in 0.001s (15.9 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_acc(y_pred, y_test):\n",
        "    y_pred_tag = y_pred.data.max(dim=-1,keepdim=True)[1]\n",
        "    y_test_tag = y_test.data.max(dim=-1,keepdim=True)[1]\n",
        "\n",
        "    batch_size = y_pred_tag.shape[0]\n",
        "    batch_acc = torch.zeros(batch_size)\n",
        "    for b in range(batch_size):\n",
        "        correct_results_sum = (y_pred_tag[b] == y_test_tag[b]).sum().float()\n",
        "        batch_acc[b] = correct_results_sum / y_pred_tag[b].shape[0]\n",
        "\n",
        "    correct_results_sum = batch_acc.sum().float()\n",
        "    acc = correct_results_sum / batch_size\n",
        "    return acc\n",
        "\n",
        "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
        "    # Defino listas para realizar graficas de los resultados\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    valid_loss = []\n",
        "    valid_accuracy = []\n",
        "\n",
        "    # Defino mi loop de entrenamiento\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        for train_encoder_input, train_decoder_input, train_target in train_loader:\n",
        "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
        "            # los va acumulando\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(train_encoder_input.to(device), train_decoder_input.to(device))\n",
        "\n",
        "            # Computo el error de la salida comparando contra las etiquetas\n",
        "            # por cada token en cada batch (sequence_loss)\n",
        "            loss = 0\n",
        "            for t in range(train_decoder_input.shape[1]):\n",
        "                loss += criterion(output[:, t, :], train_target[:, t, :])\n",
        "\n",
        "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
        "            loss.backward()\n",
        "\n",
        "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculo el accuracy del batch\n",
        "            accuracy = sequence_acc(output, train_target)\n",
        "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
        "            epoch_train_accuracy += accuracy.item()\n",
        "\n",
        "        # Calculo la media de error para la epoca de entrenamiento.\n",
        "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
        "        train_accuracy.append(epoch_train_accuracy)\n",
        "\n",
        "        # Realizo el paso de validación computando error y accuracy, y\n",
        "        # almacenando los valores para imprimirlos y graficarlos\n",
        "        valid_encoder_input, valid_decoder_input, valid_target = iter(valid_loader).next()\n",
        "        output = model(valid_encoder_input.to(device), valid_decoder_input.to(device))\n",
        "\n",
        "        epoch_valid_loss = 0\n",
        "        for t in range(train_decoder_input.shape[1]):\n",
        "                epoch_valid_loss += criterion(output[:, t, :], valid_target[:, t, :])\n",
        "        epoch_valid_loss = epoch_valid_loss.item()\n",
        "\n",
        "        valid_loss.append(epoch_valid_loss)\n",
        "\n",
        "        # Calculo el accuracy de la epoch\n",
        "        epoch_valid_accuracy = sequence_acc(output, valid_target).item()\n",
        "        valid_accuracy.append(epoch_valid_accuracy)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n",
        "\n",
        "    history = {\n",
        "        \"loss\": train_loss,\n",
        "        \"accuracy\": train_accuracy,\n",
        "        \"val_loss\": valid_loss,\n",
        "        \"val_accuracy\": valid_accuracy,\n",
        "    }\n",
        "    return history"
      ],
      "metadata": {
        "id": "tP-fbmHUgbtp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - Datos"
      ],
      "metadata": {
        "id": "5BFiCH8nxoIY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNkUaPp6aYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8788e0c-aee8-4677-8789-05777161a499"
      },
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('simpsons_dataset.zip', os.F_OK) is False:\n",
        "        url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "        output = 'spa-eng.zip'\n",
        "        gdown.download(url, output, quiet=False)\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "To: /content/spa-eng.zip\n",
            "100%|██████████| 2.64M/2.64M [00:00<00:00, 49.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9aNLZBDtA5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b312b2-ee5a-4ab5-993f-7b00c30333f3"
      },
      "source": [
        "text_file = \"./spa-eng/spa.txt\"\n",
        "with open(text_file, encoding=\"utf-8\") as f:\n",
        "    lines = f.read().strip().split(\"\\n\")\n",
        "\n",
        "print(\"Cantidad de filas totales en el archivo:\", len(lines))\n",
        "\n",
        "# Relajamos la restricción para usar más oraciones\n",
        "MAX_NUM_SENTENCES = 20000\n",
        "\n",
        "# Mezclar el dataset con semilla fija\n",
        "np.random.seed(40)\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "\n",
        "for line in lines:\n",
        "    if \"\\t\" not in line:\n",
        "        continue\n",
        "\n",
        "    # Input sentence --> eng\n",
        "    # output --> spa\n",
        "    input_sentence, output = line.rstrip().split(\"\\t\")\n",
        "\n",
        "    # output sentence (decoder_output) tiene <eos>\n",
        "    output_sentence = output + \" <eos>\"\n",
        "    # output sentence input (decoder_input) tiene <sos>\n",
        "    output_sentence_input = \"<sos> \" + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "    if len(input_sentences) >= MAX_NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))\n",
        "print(\"Ejemplo:\")\n",
        "print(\"  input :\", input_sentences[0])\n",
        "print(\"  target:\", output_sentences[0])\n",
        "print(\"  dec_in:\", output_sentences_inputs[0])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de filas totales en el archivo: 118964\n",
            "Cantidad de rows utilizadas: 20000\n",
            "Ejemplo:\n",
            "  input : Somebody stole my car.\n",
            "  target: Alguien robó mi auto. <eos>\n",
            "  dec_in: <sos> Alguien robó mi auto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93IGMKFb73q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2821c08-d0a5-48f0-e8ba-927ad917e91a"
      },
      "source": [
        "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Somebody stole my car.',\n",
              " 'Alguien robó mi auto. <eos>',\n",
              " '<sos> Alguien robó mi auto.')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WAZGOTfGyha"
      },
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 8000"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF1W6peoFGXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a4cdb1-9eb8-4ecc-c5df-e785f348a2da"
      },
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "from torch_helpers import Tokenizer\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 6812\n",
            "Sentencia de entrada más larga: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBzdKiTVIBYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fe706e-504e-4ca6-9efd-bae5a7f92b25"
      },
      "source": [
        "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras en el vocabulario: 11323\n",
            "Sentencia de salida más larga: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqb8ZJ4sJHgv"
      },
      "source": [
        "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgLC706EQx3p",
        "outputId": "ea65cb61-3a99-40d1-990e-8bd09611b0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# Longitudes de secuencias en tokens (antes de padding)\n",
        "input_lengths = np.array([len(seq) for seq in input_integer_seq])\n",
        "output_lengths = np.array([len(seq) for seq in output_integer_seq])\n",
        "\n",
        "print(\"Longitudes de las oraciones (tokens)\")\n",
        "print(f\"  Input  - min: {input_lengths.min()}, max: {input_lengths.max()}, \"\n",
        "      f\"media: {input_lengths.mean():.2f}, mediana: {np.median(input_lengths):.2f}\")\n",
        "print(f\"  Output - min: {output_lengths.min()}, max: {output_lengths.max()}, \"\n",
        "      f\"media: {output_lengths.mean():.2f}, mediana: {np.median(output_lengths):.2f}\")\n",
        "\n",
        "for p in [50, 75, 90, 95, 99]:\n",
        "    in_p = np.percentile(input_lengths, p)\n",
        "    out_p = np.percentile(output_lengths, p)\n",
        "    print(f\"  Percentil {p:>2}% -> input: {in_p:.1f} tokens, output: {out_p:.1f} tokens\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(input_lengths, bins=30, alpha=0.6, label=\"input (inglés)\")\n",
        "plt.hist(output_lengths, bins=30, alpha=0.6, label=\"output (español)\")\n",
        "plt.xlabel(\"Longitud en tokens\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.title(\"Distribución de longitudes (input vs output)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Elegir nuevas longitudes máximas menos restrictivas usando percentil 95\n",
        "max_input_len = int(np.percentile(input_lengths, 95))\n",
        "max_out_len = int(np.percentile(output_lengths, 95))\n",
        "\n",
        "print(f\"max_input_len elegido (95% de las oraciones): {max_input_len}\")\n",
        "print(f\"max_out_len elegido (95% de las oraciones): {max_out_len}\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitudes de las oraciones (tokens)\n",
            "  Input  - min: 1, max: 34, media: 6.34, mediana: 6.00\n",
            "  Output - min: 1, max: 39, media: 6.94, mediana: 7.00\n",
            "  Percentil 50% -> input: 6.0 tokens, output: 7.0 tokens\n",
            "  Percentil 75% -> input: 8.0 tokens, output: 8.0 tokens\n",
            "  Percentil 90% -> input: 10.0 tokens, output: 10.0 tokens\n",
            "  Percentil 95% -> input: 11.0 tokens, output: 12.0 tokens\n",
            "  Percentil 99% -> input: 15.0 tokens, output: 16.0 tokens\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_input_len elegido (95% de las oraciones): 11\n",
            "max_out_len elegido (95% de las oraciones): 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOn9N57IuYz"
      },
      "source": [
        "A la hora de realiza padding es importante teneer en cuenta que en el encoder los ceros se agregan al comienoz y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_sequences(\n",
        "    sequences,\n",
        "    maxlen,\n",
        "    dtype=\"int32\",\n",
        "    padding=\"pre\",\n",
        "    truncating=\"pre\",\n",
        "    value=0\n",
        "):\n",
        "    \"\"\"\n",
        "    Versión simple de pad_sequences compatible con NumPy 2.0.\n",
        "    Solo cubre el caso de secuencias numéricas (que es lo que usamos acá).\n",
        "    \"\"\"\n",
        "    num_samples = len(sequences)\n",
        "    x = np.full((num_samples, maxlen), value, dtype=dtype)\n",
        "\n",
        "    for i, seq in enumerate(sequences):\n",
        "        if seq is None:\n",
        "            continue\n",
        "        seq = list(seq)\n",
        "\n",
        "        if not len(seq):\n",
        "            continue\n",
        "\n",
        "        # Truncar\n",
        "        if truncating == \"pre\":\n",
        "            trunc = seq[-maxlen:]\n",
        "        elif truncating == \"post\":\n",
        "            trunc = seq[:maxlen]\n",
        "        else:\n",
        "            raise ValueError(\"truncating debe ser 'pre' o 'post'\")\n",
        "\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "\n",
        "        # Padding\n",
        "        if padding == \"pre\":\n",
        "            x[i, -len(trunc):] = trunc\n",
        "        elif padding == \"post\":\n",
        "            x[i, :len(trunc)] = trunc\n",
        "        else:\n",
        "            raise ValueError(\"padding debe ser 'pre' o 'post'\")\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "raeflx9Y1kMF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ob4hAWJkcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bb4658-ba1b-421d-e85d-102831a7dada"
      },
      "source": [
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de rows del dataset: 20000\n",
            "encoder_input_sequences shape: (20000, 11)\n",
            "decoder_input_sequences shape: (20000, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VySR1pzx9UG",
        "outputId": "5f9eede3-1313-44f8-a987-a824cc86202b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_output_sequences shape: (20000, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK4blEEsRQv3"
      },
      "source": [
        "La última capa del modelo (softmax) necesita que los valores de salida\n",
        "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
        "Se utiliza \"decoder_output_sequences\" con la misma estrategía que se transformó la entrada del decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(decoder_output_sequences).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANTOqJ0WWw-q",
        "outputId": "dc2b3c83-f5b8-48b6-8c92-a9a33e08d44e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20000, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
        "        # Convertir los arrays de numpy a tensores.\n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n",
        "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n",
        "        # Transformar los datos a oneHotEncoding\n",
        "        # la loss function esperan la salida float\n",
        "        self.decoder_outputs = F.one_hot(torch.from_numpy(decoder_output).to(torch.int64), num_classes=num_words_output).float()\n",
        "\n",
        "        self.len = self.decoder_outputs.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "output_dim = data_set.decoder_outputs.shape[2]\n",
        "print(\"Output dim\", output_dim)"
      ],
      "metadata": {
        "id": "SD0bpM32yWfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "sUDPZeuAU1RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OcT-DLzkHS8"
      },
      "source": [
        "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgqtV8GpkSc8"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mosj2-x-kXBK"
      },
      "source": [
        "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9FS8ca1ke_B"
      },
      "source": [
        "# Crear la Embedding matrix de las secuencias\n",
        "# en ingles\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_words"
      ],
      "metadata": {
        "id": "4q3U_WmEYRdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpzJODHBlAtE"
      },
      "source": [
        "# Dimensión de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBig(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.lstm_size = 256          # antes 128\n",
        "        self.num_layers = 2           # antes 1\n",
        "        self.embedding_dim = embed_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embedding.weight.requires_grad = False  # congelamos embeddings\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.3 if self.num_layers > 1 else 0.0,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out)\n",
        "        return (ht, ct)\n",
        "\n",
        "\n",
        "class DecoderBig(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim):\n",
        "        super().__init__()\n",
        "        self.lstm_size = 256\n",
        "        self.num_layers = 2\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.3 if self.num_layers > 1 else 0.0,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        out = self.softmax(self.fc1(lstm_output[:, -1, :]))  # último paso de la secuencia\n",
        "        return out, (ht, ct)\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        assert encoder.lstm_size == decoder.lstm_size, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.num_layers == decoder.num_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        batch_size = decoder_input.shape[0]\n",
        "        decoder_input_len = decoder_input.shape[1]\n",
        "        vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # tensor para almacenar la salida\n",
        "        # (batch_size, sentence_len, one_hot_size)\n",
        "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size)\n",
        "\n",
        "        # ultimo hidden state del encoder, primer estado oculto del decoder\n",
        "        prev_state = self.encoder(encoder_input)\n",
        "\n",
        "        # En la primera iteracion se toma el primer token de target ()\n",
        "        input = decoder_input[:, 0:1]\n",
        "\n",
        "        for t in range(decoder_input_len):\n",
        "            # t --> token index\n",
        "\n",
        "            # utilizamos método \"teacher forcing\", es decir que durante\n",
        "            # el entrenamiento no realimentamos la salida del decoder\n",
        "            # sino el token correcto que sigue en target\n",
        "            input = decoder_input[:, t:t+1]\n",
        "\n",
        "            # ingresar cada token embedding, uno por uno junto al hidden state\n",
        "            # recibir el output del decoder (softmax)\n",
        "            output, prev_state = self.decoder(input, prev_state)\n",
        "            top1 = output.argmax(1).view(-1, 1)\n",
        "\n",
        "            # Sino se usará \"teacher forcing\" habría que descomentar\n",
        "            # esta linea.\n",
        "            # Hay ejemplos dandos vuelta en donde se utilza un random\n",
        "            # para ver en cada vuelta que técnica se aplica\n",
        "            #input = top1\n",
        "\n",
        "            # guardar cada salida (softmax)\n",
        "            outputs[:, t, :] = output\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "g5qwNRcDyUa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_big = EncoderBig(vocab_size=nb_words)\n",
        "decoder_big = DecoderBig(vocab_size=num_words_output, output_dim=num_words_output)\n",
        "\n",
        "if cuda:\n",
        "    encoder_big.cuda()\n",
        "    decoder_big.cuda()\n",
        "\n",
        "model_big = Seq2Seq(encoder_big, decoder_big)\n",
        "if cuda:\n",
        "    model_big.cuda()\n",
        "\n",
        "optimizer_big = torch.optim.Adam(model_big.parameters(), lr=0.001)  # lr más chico para modelo más grande\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "summary(model_big, input_data=(data_set[0:1][0], data_set[0:1][1]))"
      ],
      "metadata": {
        "id": "JvaVwC9CyaXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_big = train(\n",
        "    model_big,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    optimizer_big,\n",
        "    criterion,\n",
        "    epochs=15   # algunas épocas más para el modelo grande\n",
        ")"
      ],
      "metadata": {
        "id": "bW8tJBncyeq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = range(1, len(history_big['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_big['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history_big['val_accuracy'], label='valid')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pZzm3tx059Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversores de índice a palabra\n",
        "idx2word_input = {v: k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v: k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "def translate_sentence(model, sentence, max_len=max_out_len):\n",
        "    model.eval()\n",
        "\n",
        "    # Texto → ids\n",
        "    integer_seq = input_tokenizer.texts_to_sequences([sentence])[0]\n",
        "    encoder_seq = pad_sequences([integer_seq], maxlen=max_input_len)\n",
        "    encoder_tensor = torch.from_numpy(encoder_seq.astype(np.int32)).to(device)\n",
        "\n",
        "    # Estado inicial del decoder desde el encoder\n",
        "    prev_state = model.encoder(encoder_tensor)\n",
        "\n",
        "    # Token inicial <sos>\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs[\"<sos>\"]\n",
        "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32)).to(device)\n",
        "\n",
        "    eos = word2idx_outputs[\"<eos>\"]\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        output, prev_state = model.decoder(target_seq_tensor, prev_state)\n",
        "        top1 = output.argmax(1).view(-1, 1)\n",
        "        idx = int(top1.cpu())\n",
        "\n",
        "        if idx == eos:\n",
        "            break\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target.get(idx, \"\")\n",
        "            if word:\n",
        "                output_sentence.append(word)\n",
        "\n",
        "        # re-alimentar el token predicho\n",
        "        target_seq_tensor = top1.to(device)\n",
        "\n",
        "    return \" \".join(output_sentence)\n"
      ],
      "metadata": {
        "id": "I_y_BxUGzfWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos manuales\n",
        "test_sentences = [\n",
        "    \"How are you?\",\n",
        "    \"My mother says hi.\",\n",
        "    \"I like to learn machine learning.\",\n",
        "    \"This restaurant is very good.\",\n",
        "    \"I will call you tomorrow.\"\n",
        "]\n",
        "\n",
        "print(\"=== Traducciones (modelo grande) ===\")\n",
        "for s in test_sentences:\n",
        "    print(\"-\" * 50)\n",
        "    print(\"EN:\", s)\n",
        "    print(\"ES:\", translate_sentence(model_big, s))\n",
        "\n",
        "# Ejemplos tomados del dataset (para comparar con la referencia)\n",
        "print(\"\\n=== Ejemplos del dataset ===\")\n",
        "for _ in range(5):\n",
        "    i = np.random.randint(len(input_sentences))\n",
        "    src = input_sentences[i]\n",
        "    tgt = output_sentences[i]\n",
        "    pred = translate_sentence(model_big, src)\n",
        "    print(\"-\" * 50)\n",
        "    print(\"EN      :\", src)\n",
        "    print(\"ES real :\", tgt)\n",
        "    print(\"ES pred :\", pred)\n"
      ],
      "metadata": {
        "id": "sgVnQa7tzia0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}