{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Desafio 4 - Rodrigues da Cruz (a2123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "El objecto es utilizar datos disponibles de Anki de traducciones de texto en diferentes idiomas. Se construirá un modelo traductor seq2seq utilizando encoder-decoder. Cada fila tiene una frase en inglés, su traducción al español y algo de información extra que no usamos. La idea es quedarnos solo con dos listas limpias de frases alineadas, una en inglés y otra en español, para entrenar después el modelo encoder–decoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgYatMIdk_eT",
        "outputId": "a2029a8c-53e7-4712-f645-2153960dd833"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYpIWGaXxfKe",
        "outputId": "1bda33f7-569f-4901-b74c-fde7d5ecf859"
      },
      "outputs": [],
      "source": [
        "# torchsummar actualmente tiene un problema con las LSTM, por eso\n",
        "# se utiliza torchinfo, un fork del proyecto original con el bug solucionado\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHFPS5KNxgR9",
        "outputId": "7748e26e-5bb9-4496-896f-30fd1e4e3d97"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tP-fbmHUgbtp"
      },
      "outputs": [],
      "source": [
        "def sequence_acc(y_pred, y_test):\n",
        "    y_pred_tag = y_pred.data.max(dim=-1,keepdim=True)[1]\n",
        "    y_test_tag = y_test.data.max(dim=-1,keepdim=True)[1]\n",
        "\n",
        "    batch_size = y_pred_tag.shape[0]\n",
        "    batch_acc = torch.zeros(batch_size)\n",
        "    for b in range(batch_size):\n",
        "        correct_results_sum = (y_pred_tag[b] == y_test_tag[b]).sum().float()\n",
        "        batch_acc[b] = correct_results_sum / y_pred_tag[b].shape[0]\n",
        "\n",
        "    correct_results_sum = batch_acc.sum().float()\n",
        "    acc = correct_results_sum / batch_size\n",
        "    return acc\n",
        "\n",
        "def train(model, train_loader, valid_loader, optimizer, epochs=15, pad_index=0):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "    train_loss_history = []\n",
        "    valid_loss_history = []\n",
        "    train_acc_history = []\n",
        "    valid_acc_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ------------------ TRAIN ------------------\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        correct_tokens = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        for encoder_input, decoder_input, target_onehot in train_loader:\n",
        "            encoder_input = encoder_input.to(device)\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            target_onehot = target_onehot.to(device)  # (B, T, V)\n",
        "\n",
        "            # one-hot -> índices (B, T)\n",
        "            target_idx = target_onehot.argmax(dim=-1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # logits: (B, T, V)\n",
        "            outputs = model(encoder_input, decoder_input)\n",
        "\n",
        "            B, T, V = outputs.shape\n",
        "            outputs_flat = outputs.view(B * T, V)\n",
        "            targets_flat = target_idx.view(B * T)\n",
        "\n",
        "            loss = criterion(outputs_flat, targets_flat)\n",
        "            loss.backward()\n",
        "\n",
        "            # pequeño clipping para evitar explosión de gradientes\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds_flat = outputs_flat.argmax(dim=-1)\n",
        "                mask = targets_flat != pad_index\n",
        "                correct_tokens += (preds_flat[mask] == targets_flat[mask]).sum().item()\n",
        "                total_tokens += mask.sum().item()\n",
        "\n",
        "        epoch_train_loss /= len(train_loader)\n",
        "        epoch_train_acc = correct_tokens / max(total_tokens, 1)\n",
        "        train_loss_history.append(epoch_train_loss)\n",
        "        train_acc_history.append(epoch_train_acc)\n",
        "\n",
        "        # ------------------ VALID ------------------\n",
        "        model.eval()\n",
        "        epoch_valid_loss = 0.0\n",
        "        correct_tokens = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for encoder_input, decoder_input, target_onehot in valid_loader:\n",
        "                encoder_input = encoder_input.to(device)\n",
        "                decoder_input = decoder_input.to(device)\n",
        "                target_onehot = target_onehot.to(device)\n",
        "\n",
        "                target_idx = target_onehot.argmax(dim=-1)\n",
        "\n",
        "                outputs = model(encoder_input, decoder_input)\n",
        "\n",
        "                B, T, V = outputs.shape\n",
        "                outputs_flat = outputs.view(B * T, V)\n",
        "                targets_flat = target_idx.view(B * T)\n",
        "\n",
        "                loss = criterion(outputs_flat, targets_flat)\n",
        "                epoch_valid_loss += loss.item()\n",
        "\n",
        "                preds_flat = outputs_flat.argmax(dim=-1)\n",
        "                mask = targets_flat != pad_index\n",
        "                correct_tokens += (preds_flat[mask] == targets_flat[mask]).sum().item()\n",
        "                total_tokens += mask.sum().item()\n",
        "\n",
        "        epoch_valid_loss /= len(valid_loader)\n",
        "        epoch_valid_acc = correct_tokens / max(total_tokens, 1)\n",
        "\n",
        "        valid_loss_history.append(epoch_valid_loss)\n",
        "        valid_acc_history.append(epoch_valid_acc)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{epochs} | \"\n",
        "            f\"loss: {epoch_train_loss:.3f} - acc: {epoch_train_acc:.3f} | \"\n",
        "            f\"val_loss: {epoch_valid_loss:.3f} - val_acc: {epoch_valid_acc:.3f}\"\n",
        "        )\n",
        "\n",
        "    history = {\n",
        "        \"loss\": train_loss_history,\n",
        "        \"accuracy\": train_acc_history,\n",
        "        \"val_loss\": valid_loss_history,\n",
        "        \"val_accuracy\": valid_acc_history,\n",
        "    }\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BFiCH8nxoIY"
      },
      "source": [
        "### 1 - Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHNkUaPp6aYq",
        "outputId": "b8788e0c-aee8-4677-8789-05777161a499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('spa-eng', os.F_OK) is False:\n",
        "    if os.access('simpsons_dataset.zip', os.F_OK) is False:\n",
        "        url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
        "        output = 'spa-eng.zip'\n",
        "        gdown.download(url, output, quiet=False)\n",
        "    !unzip -q spa-eng.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9aNLZBDtA5J",
        "outputId": "01b312b2-ee5a-4ab5-993f-7b00c30333f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows disponibles en el archivo: 118964\n",
            "Original número de oraciones (antes de balancear): 20000\n",
            "\n",
            "Top 15 bigrams iniciales:\n",
            "tom no                    377\n",
            "tom se                    189\n",
            "¿por qué                  181\n",
            "tom es                    162\n",
            "no me                     135\n",
            "creo que                  125\n",
            "por favor,                105\n",
            "no quiero                 99\n",
            "tom está                  92\n",
            "él es                     91\n",
            "tom le                    91\n",
            "tom y                     88\n",
            "no puedo                  87\n",
            "él se                     76\n",
            "pensé que                 73\n",
            "\n",
            "Número de oraciones tras balancear por inicio: 19923\n",
            "Cantidad de rows utilizadas finalmente: 19923\n",
            "\n",
            "Ejemplo 1:\n",
            "  EN     : Somebody stole my car.\n",
            "  ES real: Alguien robó mi auto. <eos>\n",
            "  dec_in : <sos> Alguien robó mi auto.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "text_file = \"C:/Users/n.rodrigues.da.cruz/Downloads/spa-eng/spa-eng/spa.txt\"\n",
        "with open(text_file, encoding=\"utf-8\") as f:\n",
        "    lines = f.read().strip().split(\"\\n\")\n",
        "\n",
        "print(\"Cantidad de rows disponibles en el archivo:\", len(lines))\n",
        "\n",
        "# Relajamos cantidad de datos (más que 6000)\n",
        "MAX_NUM_SENTENCES = 20000  \n",
        "\n",
        "np.random.seed(40)\n",
        "np.random.shuffle(lines)\n",
        "\n",
        "raw_input_sentences = []\n",
        "raw_output_sentences = []\n",
        "raw_output_sentences_inputs = []\n",
        "\n",
        "for line in lines:\n",
        "    if \"\\t\" not in line:\n",
        "        continue\n",
        "\n",
        "    input_sentence, output = line.rstrip().split(\"\\t\")\n",
        "\n",
        "    output_sentence = output + \" <eos>\"\n",
        "    output_sentence_input = \"<sos> \" + output\n",
        "\n",
        "    raw_input_sentences.append(input_sentence)\n",
        "    raw_output_sentences.append(output_sentence)\n",
        "    raw_output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "    if len(raw_input_sentences) >= MAX_NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "print(\"Original número de oraciones (antes de balancear):\", len(raw_input_sentences))\n",
        "\n",
        "# --- EDA rápida de comienzos (opcional, pero útil para comentar en el TP) ---\n",
        "\n",
        "start_bigrams = Counter()\n",
        "for out in raw_output_sentences:\n",
        "    text = out.replace(\"<eos>\", \"\").strip().lower()\n",
        "    tokens = text.split()\n",
        "    if len(tokens) == 0:\n",
        "        continue\n",
        "    bigram = \" \".join(tokens[:2]) if len(tokens) >= 2 else tokens[0]\n",
        "    start_bigrams[bigram] += 1\n",
        "\n",
        "print(\"\\nTop 15 bigrams iniciales:\")\n",
        "for w, c in start_bigrams.most_common(15):\n",
        "    print(f\"{w:25s} {c}\")\n",
        "\n",
        "# --- Balanceo por bigrama inicial ---\n",
        "\n",
        "MAX_PER_START = 300  # máximo de ejemplos por bigrama de inicio\n",
        "\n",
        "start_to_indices = defaultdict(list)\n",
        "for idx, out in enumerate(raw_output_sentences):\n",
        "    text = out.replace(\"<eos>\", \"\").strip().lower()\n",
        "    tokens = text.split()\n",
        "    if len(tokens) == 0:\n",
        "        continue\n",
        "    bigram = \" \".join(tokens[:2]) if len(tokens) >= 2 else tokens[0]\n",
        "    start_to_indices[bigram].append(idx)\n",
        "\n",
        "selected_indices = []\n",
        "\n",
        "for bigram, idxs in start_to_indices.items():\n",
        "    if len(idxs) <= MAX_PER_START:\n",
        "        selected_indices.extend(idxs)\n",
        "    else:\n",
        "        # tomamos una muestra al azar de tamaño MAX_PER_START\n",
        "        chosen = np.random.choice(idxs, size=MAX_PER_START, replace=False)\n",
        "        selected_indices.extend(chosen)\n",
        "\n",
        "# Nos aseguramos de no repetir índices y los ordenamos\n",
        "selected_indices = sorted(set(selected_indices))\n",
        "\n",
        "print(\"\\nNúmero de oraciones tras balancear por inicio:\", len(selected_indices))\n",
        "\n",
        "input_sentences = [raw_input_sentences[i] for i in selected_indices]\n",
        "output_sentences = [raw_output_sentences[i] for i in selected_indices]\n",
        "output_sentences_inputs = [raw_output_sentences_inputs[i] for i in selected_indices]\n",
        "\n",
        "print(\"Cantidad de rows utilizadas finalmente:\", len(input_sentences))\n",
        "print(\"\\nEjemplo 1:\")\n",
        "print(\"  EN     :\", input_sentences[0])\n",
        "print(\"  ES real:\", output_sentences[0])\n",
        "print(\"  dec_in :\", output_sentences_inputs[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93IGMKFb73q7",
        "outputId": "d2821c08-d0a5-48f0-e8ba-927ad917e91a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Somebody stole my car.',\n",
              " 'Alguien robó mi auto. <eos>',\n",
              " '<sos> Alguien robó mi auto.')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Acá miramos un ejemplo para ver si el preprocesamiento tiene sentido.  \n",
        "`input_sentences` guarda la oración original en inglés, `output_sentences` es la traducción en español y `output_sentences_inputs` es la versión “corrida” que empieza con el token `<sos>`.  \n",
        "Esta versión corrida es la que va leyendo el decodificador durante el entrenamiento, palabra por palabra.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P-ynUNP5xp6"
      },
      "source": [
        "### 2 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5WAZGOTfGyha"
      },
      "outputs": [],
      "source": [
        "# Definir el tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF1W6peoFGXA",
        "outputId": "f9a4cdb1-9eb8-4ecc-c5df-e785f348a2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 6806\n",
            "Sentencia de entrada más larga: 34\n"
          ]
        }
      ],
      "source": [
        "# Tokenizar las palabras con el Tokenizer de Keras\n",
        "# Definir una máxima cantidad de palabras a utilizar:\n",
        "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
        "# - Only the most common num_words-1 words will be kept.\n",
        "from torch_helpers import Tokenizer\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBzdKiTVIBYY",
        "outputId": "f0fe706e-504e-4ca6-9efd-bae5a7f92b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 11310\n",
            "Sentencia de salida más larga: 43\n"
          ]
        }
      ],
      "source": [
        "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
        "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Sentencia de salida más larga:\", max_out_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqb8ZJ4sJHgv"
      },
      "source": [
        "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "pgLC706EQx3p",
        "outputId": "ea65cb61-3a99-40d1-990e-8bd09611b0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitudes de las oraciones (tokens)\n",
            "  Input  - min: 1, max: 34, media: 6.33, mediana: 6.00\n",
            "  Output - min: 1, max: 43, media: 7.03, mediana: 7.00\n",
            "  Percentil 50% -> input: 6.0 tokens, output: 7.0 tokens\n",
            "  Percentil 75% -> input: 8.0 tokens, output: 8.0 tokens\n",
            "  Percentil 90% -> input: 10.0 tokens, output: 11.0 tokens\n",
            "  Percentil 95% -> input: 11.0 tokens, output: 12.0 tokens\n",
            "  Percentil 99% -> input: 15.0 tokens, output: 16.0 tokens\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_input_len: 10\n",
            "max_out_len: 11\n",
            "max_input_len elegido (95% de las oraciones): 10\n",
            "max_out_len elegido (95% de las oraciones): 11\n"
          ]
        }
      ],
      "source": [
        "# Longitudes de secuencias en tokens (antes de padding)\n",
        "input_lengths = np.array([len(seq) for seq in input_integer_seq])\n",
        "output_lengths = np.array([len(seq) for seq in output_integer_seq])\n",
        "\n",
        "print(\"Longitudes de las oraciones (tokens)\")\n",
        "print(f\"  Input  - min: {input_lengths.min()}, max: {input_lengths.max()}, \"\n",
        "      f\"media: {input_lengths.mean():.2f}, mediana: {np.median(input_lengths):.2f}\")\n",
        "print(f\"  Output - min: {output_lengths.min()}, max: {output_lengths.max()}, \"\n",
        "      f\"media: {output_lengths.mean():.2f}, mediana: {np.median(output_lengths):.2f}\")\n",
        "\n",
        "for p in [50, 75, 90, 95, 99]:\n",
        "    in_p = np.percentile(input_lengths, p)\n",
        "    out_p = np.percentile(output_lengths, p)\n",
        "    print(f\"  Percentil {p:>2}% -> input: {in_p:.1f} tokens, output: {out_p:.1f} tokens\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(input_lengths, bins=30, alpha=0.6, label=\"input (inglés)\")\n",
        "plt.hist(output_lengths, bins=30, alpha=0.6, label=\"output (español)\")\n",
        "plt.xlabel(\"Longitud en tokens\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.title(\"Distribución de longitudes (input vs output)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Elegir nuevas longitudes máximas menos restrictivas usando percentil 95\n",
        "max_input_len = int(np.percentile(input_lengths, 90))\n",
        "max_out_len   = int(np.percentile(output_lengths, 90))\n",
        "\n",
        "# Tope razonable (relajado respecto al TP, pero no extremo)\n",
        "max_input_len = min(max_input_len, 20)\n",
        "max_out_len   = min(max_out_len, 22)\n",
        "\n",
        "print(\"max_input_len:\", max_input_len)\n",
        "print(\"max_out_len:\", max_out_len)\n",
        "\n",
        "\n",
        "print(f\"max_input_len elegido (95% de las oraciones): {max_input_len}\")\n",
        "print(f\"max_out_len elegido (95% de las oraciones): {max_out_len}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estas estadísticas nos ayudan a elegir longitudes máximas razonables para hacer el padding.   Mirando los percentiles vemos qué tan largas son la mayoría de las oraciones y podemos ignorar solo los casos extremos.   Usar el percentil 95 es un buen compromiso: mantenemos casi todas las oraciones sin hacerlas demasiado largas, lo que ahorra memoria y acelera el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOn9N57IuYz"
      },
      "source": [
        "A la hora de realiza padding es importante teneer en cuenta que en el encoder los ceros se agregan al comienoz y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "raeflx9Y1kMF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_sequences(\n",
        "    sequences,\n",
        "    maxlen,\n",
        "    dtype=\"int32\",\n",
        "    padding=\"pre\",\n",
        "    truncating=\"pre\",\n",
        "    value=0\n",
        "):\n",
        "    \"\"\"\n",
        "    Versión simple de pad_sequences compatible con NumPy 2.0.\n",
        "    Solo cubre el caso de secuencias numéricas (que es lo que usamos acá).\n",
        "    \"\"\"\n",
        "    num_samples = len(sequences)\n",
        "    x = np.full((num_samples, maxlen), value, dtype=dtype)\n",
        "\n",
        "    for i, seq in enumerate(sequences):\n",
        "        if seq is None:\n",
        "            continue\n",
        "        seq = list(seq)\n",
        "\n",
        "        if not len(seq):\n",
        "            continue\n",
        "\n",
        "        # Truncar\n",
        "        if truncating == \"pre\":\n",
        "            trunc = seq[-maxlen:]\n",
        "        elif truncating == \"post\":\n",
        "            trunc = seq[:maxlen]\n",
        "        else:\n",
        "            raise ValueError(\"truncating debe ser 'pre' o 'post'\")\n",
        "\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "\n",
        "        # Padding\n",
        "        if padding == \"pre\":\n",
        "            x[i, -len(trunc):] = trunc\n",
        "        elif padding == \"post\":\n",
        "            x[i, :len(trunc)] = trunc\n",
        "        else:\n",
        "            raise ValueError(\"padding debe ser 'pre' o 'post'\")\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Ob4hAWJkcv",
        "outputId": "07bb4658-ba1b-421d-e85d-102831a7dada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows del dataset: 19923\n",
            "encoder_input_sequences shape: (19923, 10)\n",
            "decoder_input_sequences shape: (19923, 11)\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VySR1pzx9UG",
        "outputId": "5f9eede3-1313-44f8-a987-a824cc86202b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder_output_sequences shape: (19923, 11)\n"
          ]
        }
      ],
      "source": [
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La función `pad_sequences` hace que todas las secuencias tengan el mismo largo agregando tokens de relleno (ceros).   Hacer el padding al final (`padding='post'`) mantiene el orden de las palabras reales y deja el relleno al final.  Esto es importante porque el modelo aprende que el cero significa “no hay palabra” y se concentra en la parte útil de cada secuencia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_sequences max index: 6806\n",
            "decoder_input_sequences max index: 9999\n",
            "input_vocab_size real: 6807\n",
            "output_vocab_size real: 10000\n"
          ]
        }
      ],
      "source": [
        "print(\"encoder_input_sequences max index:\", encoder_input_sequences.max())\n",
        "print(\"decoder_input_sequences max index:\", decoder_input_sequences.max())\n",
        "\n",
        "input_vocab_size = int(encoder_input_sequences.max()) + 1\n",
        "output_vocab_size = int(decoder_input_sequences.max()) + 1\n",
        "\n",
        "print(\"input_vocab_size real:\", input_vocab_size)\n",
        "print(\"output_vocab_size real:\", output_vocab_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los tamaños reales de vocabulario nos dicen cuántos IDs de tokens diferentes necesitamos en las capas de embedding.   Sumamos 1 al índice máximo porque el índice 0 lo reservamos para el padding.   Con estos valores definimos el tamaño de las tablas que convierten cada ID de token en un vector denso (embedding)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK4blEEsRQv3"
      },
      "source": [
        "La última capa del modelo (softmax) necesita que los valores de salida\n",
        "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
        "Se utiliza \"decoder_output_sequences\" con la misma estrategía que se transformó la entrada del decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANTOqJ0WWw-q",
        "outputId": "dc2b3c83-f5b8-48b6-8c92-a9a33e08d44e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([19923, 11])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.from_numpy(decoder_output_sequences).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SD0bpM32yWfB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_size: 10\n",
            "decoder_input_size: 11\n",
            "Output dim 10000\n"
          ]
        }
      ],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
        "        # Convertir los arrays de numpy a tensores.\n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n",
        "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n",
        "        # Transformar los datos a oneHotEncoding\n",
        "        # la loss function esperan la salida float\n",
        "        self.decoder_outputs = F.one_hot(torch.from_numpy(decoder_output).to(torch.int64), num_classes=num_words_output).float()\n",
        "\n",
        "        self.len = self.decoder_outputs.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
        "\n",
        "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
        "print(\"encoder_input_size:\", encoder_input_size)\n",
        "\n",
        "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
        "print(\"decoder_input_size:\", decoder_input_size)\n",
        "\n",
        "output_dim = data_set.decoder_outputs.shape[2]\n",
        "print(\"Output dim\", output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sUDPZeuAU1RI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del conjunto de entrenamiento: 15939\n",
            "Tamaño del conjunto de validacion: 3984\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "valid_set_size = int(data_set.len * 0.2)\n",
        "train_set_size = data_set.len - valid_set_size\n",
        "\n",
        "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
        "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
        "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Acá envolvemos los arrays de NumPy en un df de PyTorch para que el modelo pueda iterar en mini-batches.   También separamos los datos en un conjunto de entrenamiento y otro de validación.   El conjunto de entrenamiento sirve para ajustar los pesos del modelo y el de validación para ver qué tan bien generaliza a ejemplos que no vio durante el entrenamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9OcT-DLzkHS8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los embeddings gloveembedding.pkl ya están descargados\n"
          ]
        }
      ],
      "source": [
        "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
        "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
        "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
        "import os\n",
        "import gdown\n",
        "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
        "    output = 'gloveembedding.pkl'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZgqtV8GpkSc8"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "\n",
        "class WordsEmbeddings(object):\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    def __init__(self):\n",
        "        # load the embeddings\n",
        "        words_embedding_pkl = Path(self.PKL_PATH)\n",
        "        if not words_embedding_pkl.is_file():\n",
        "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
        "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
        "            embeddings = self.convert_model_to_pickle()\n",
        "        else:\n",
        "            embeddings = self.load_model_from_pickle()\n",
        "        self.embeddings = embeddings\n",
        "        # build the vocabulary hashmap\n",
        "        index = np.arange(self.embeddings.shape[0])\n",
        "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
        "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
        "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
        "\n",
        "    def get_words_embeddings(self, words):\n",
        "        words_idxs = self.words2idxs(words)\n",
        "        return self.embeddings[words_idxs]['embedding']\n",
        "\n",
        "    def words2idxs(self, words):\n",
        "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
        "\n",
        "    def idxs2words(self, idxs):\n",
        "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
        "\n",
        "    def load_model_from_pickle(self):\n",
        "        self.logger.debug(\n",
        "            'loading words embeddings from pickle {}'.format(\n",
        "                self.PKL_PATH\n",
        "            )\n",
        "        )\n",
        "        max_bytes = 2**28 - 1 # 256MB\n",
        "        bytes_in = bytearray(0)\n",
        "        input_size = os.path.getsize(self.PKL_PATH)\n",
        "        with open(self.PKL_PATH, 'rb') as f_in:\n",
        "            for _ in range(0, input_size, max_bytes):\n",
        "                bytes_in += f_in.read(max_bytes)\n",
        "        embeddings = pickle.loads(bytes_in)\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "    def convert_model_to_pickle(self):\n",
        "        # create a numpy strctured array:\n",
        "        # word     embedding\n",
        "        # U50      np.float32[]\n",
        "        # word_1   a, b, c\n",
        "        # word_2   d, e, f\n",
        "        # ...\n",
        "        # word_n   g, h, i\n",
        "        self.logger.debug(\n",
        "            'converting and loading words embeddings from text file {}'.format(\n",
        "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
        "            )\n",
        "        )\n",
        "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
        "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
        "        structure = np.dtype(structure)\n",
        "        # load numpy array from disk using a generator\n",
        "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
        "            embeddings_gen = (\n",
        "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
        "                if len(line.split()[1:]) == self.N_FEATURES\n",
        "            )\n",
        "            embeddings = np.fromiter(embeddings_gen, structure)\n",
        "        # add a null embedding\n",
        "        null_embedding = np.array(\n",
        "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
        "            dtype=structure\n",
        "        )\n",
        "        embeddings = np.concatenate([embeddings, null_embedding])\n",
        "        # dump numpy array to disk using pickle\n",
        "        max_bytes = 2**28 - 1 # # 256MB\n",
        "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.PKL_PATH, 'wb') as f_out:\n",
        "            for idx in range(0, len(bytes_out), max_bytes):\n",
        "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
        "        self.logger.debug('words embeddings loaded')\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class GloveEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
        "    PKL_PATH = 'gloveembedding.pkl'\n",
        "    N_FEATURES = 50\n",
        "    WORD_MAX_SIZE = 60\n",
        "\n",
        "class FasttextEmbeddings(WordsEmbeddings):\n",
        "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
        "    PKL_PATH = 'fasttext.pkl'\n",
        "    N_FEATURES = 300\n",
        "    WORD_MAX_SIZE = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Mosj2-x-kXBK"
      },
      "outputs": [],
      "source": [
        "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
        "model_embeddings = GloveEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b9FS8ca1ke_B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preparing embedding matrix...\n",
            "number of null word embeddings: 80\n"
          ]
        }
      ],
      "source": [
        "# Crear la Embedding matrix de las secuencias\n",
        "# en ingles\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.N_FEATURES\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este paso preparamos la matriz de embeddings para el vocabulario en inglés usando vectores GloVe pre-entrenados.   Si una palabra existe en GloVe, copiamos su vector a la matriz; si no, se queda con un vector de ceros.   Esto le da al modelo un buen punto de partida, porque muchas palabras ya vienen con información semántica aprendida de un corpus grande.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4q3U_WmEYRdH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6806"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FpzJODHBlAtE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6806, 50)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimensión de los embeddings de la secuencia en ingles\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5qwNRcDyUa5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# usá el mismo embed_dim que ya venías usando (por ej. 100 o 300)\n",
        "# si en tu notebook se llama distinto, respetá ese nombre\n",
        "embedding_dim = embed_dim  # si tu variable es embed_dim\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input):\n",
        "        device = encoder_input.device\n",
        "\n",
        "        batch_size = encoder_input.size(0)\n",
        "        decoder_input_len = decoder_input.size(1)\n",
        "        vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # IMPORTANTE: outputs en el mismo device\n",
        "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size, device=device)\n",
        "\n",
        "        # estado inicial del decoder = estado final del encoder\n",
        "        prev_state = self.encoder(encoder_input)\n",
        "\n",
        "        # primer token del decoder (normalmente <sos>)\n",
        "        input_step = decoder_input[:, 0:1]\n",
        "\n",
        "        for t in range(decoder_input_len):\n",
        "            logits, prev_state = self.decoder(input_step, prev_state)\n",
        "            outputs[:, t, :] = logits\n",
        "            # teacher forcing: siguiente entrada es el token real\n",
        "            input_step = decoder_input[:, t:t+1]\n",
        "\n",
        "        return outputs  # shape: (B, T, V) con LOGITS\n",
        "    \n",
        "\n",
        "class EncoderMid(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.lstm_size = 128        # en vez de 256\n",
        "        self.num_layers = 1         # una sola capa\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.0,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x)\n",
        "        _, (ht, ct) = self.lstm(out)\n",
        "        return (ht, ct)\n",
        "\n",
        "\n",
        "class DecoderMid(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim):\n",
        "        super().__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.num_layers = 1\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            batch_first=True,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.0,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(self.lstm_size, self.output_dim)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        out = self.embedding(x)\n",
        "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
        "        logits = self.fc1(lstm_output[:, -1, :])\n",
        "        return logits, (ht, ct)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La arquitectura es un modelo clásico de secuencia a secuencia basado en LSTMs.   El encoder lee toda la oración en inglés y la resume en un estado oculto.   El decoder usa ese estado para generar la traducción al español, token por token.  Usamos una sola capa LSTM y un tamaño de estado oculto más chico para tener un modelo liviano y rápido de entrenar, pero que igual pueda manejar oraciones cortas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JvaVwC9CyaXQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | loss: 6.145 - acc: 0.175 | val_loss: 5.521 - val_acc: 0.204\n",
            "Epoch 2/10 | loss: 5.469 - acc: 0.222 | val_loss: 5.175 - val_acc: 0.240\n",
            "Epoch 3/10 | loss: 5.057 - acc: 0.256 | val_loss: 4.907 - val_acc: 0.266\n",
            "Epoch 4/10 | loss: 4.683 - acc: 0.283 | val_loss: 4.716 - val_acc: 0.285\n",
            "Epoch 5/10 | loss: 4.348 - acc: 0.306 | val_loss: 4.580 - val_acc: 0.297\n",
            "Epoch 6/10 | loss: 4.040 - acc: 0.323 | val_loss: 4.489 - val_acc: 0.303\n",
            "Epoch 7/10 | loss: 3.755 - acc: 0.339 | val_loss: 4.416 - val_acc: 0.312\n",
            "Epoch 8/10 | loss: 3.484 - acc: 0.355 | val_loss: 4.368 - val_acc: 0.317\n",
            "Epoch 9/10 | loss: 3.238 - acc: 0.374 | val_loss: 4.346 - val_acc: 0.322\n",
            "Epoch 10/10 | loss: 3.007 - acc: 0.395 | val_loss: 4.329 - val_acc: 0.323\n"
          ]
        }
      ],
      "source": [
        "input_vocab_size  = int(encoder_input_sequences.max()) + 1\n",
        "output_vocab_size = int(decoder_input_sequences.max()) + 1\n",
        "\n",
        "encoder_mid = EncoderMid(vocab_size=input_vocab_size)\n",
        "decoder_mid = DecoderMid(vocab_size=output_vocab_size, output_dim=output_vocab_size)\n",
        "\n",
        "if cuda:\n",
        "    encoder_mid.cuda()\n",
        "    decoder_mid.cuda()\n",
        "\n",
        "model_mid = Seq2Seq(encoder_mid, decoder_mid)\n",
        "if cuda:\n",
        "    model_mid.cuda()\n",
        "\n",
        "optimizer_mid = torch.optim.Adam(model_mid.parameters(), lr=0.001)\n",
        "\n",
        "history_mid = train(\n",
        "    model_mid,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    optimizer_mid,\n",
        "    epochs=10,\n",
        "    pad_index=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La función train corre varias épocas sobre el conjunto de entrenamiento y actualiza los parámetros del modelo con el optimizador Adam.  Al final de cada época también evalúa el modelo en el conjunto de validación y guarda la historia de accuracy.  Esa historia la usamos después para graficar cómo cambian el accuracy de entrenamiento y de validación a lo largo de las épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pZzm3tx059Zv"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch_count = range(1, len(history_mid['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_mid['accuracy'], label='train')\n",
        "sns.lineplot(x=epoch_count,  y=history_mid['val_accuracy'], label='valid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este gráfico nos muestra si el modelo realmente está aprendiendo.  Esperamos que el accuracy de entrenamiento y de validación vaya subiendo con las épocas.  Si el accuracy de entrenamiento es mucho más alto que el de validación, el modelo puede estar sobreajustando. Pequeñas diferencias con los resultados de la notebook original son normales y pueden deberse a la inicialización aleatoria, a versiones distintas de librerías o al hardware.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "I_y_BxUGzfWF"
      },
      "outputs": [],
      "source": [
        "# Conversores de índice a palabra\n",
        "idx2word_input = {v: k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v: k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "def translate_sentence(model, sentence, max_len=max_out_len):\n",
        "    model.eval()\n",
        "\n",
        "    # Texto → ids\n",
        "    integer_seq = input_tokenizer.texts_to_sequences([sentence])[0]\n",
        "    encoder_seq = pad_sequences([integer_seq], maxlen=max_input_len)\n",
        "    encoder_tensor = torch.from_numpy(encoder_seq.astype(np.int32)).to(device)\n",
        "\n",
        "    # Estado inicial del decoder desde el encoder\n",
        "    prev_state = model.encoder(encoder_tensor)\n",
        "\n",
        "    # Token inicial <sos>\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs[\"<sos>\"]\n",
        "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32)).to(device)\n",
        "\n",
        "    eos = word2idx_outputs[\"<eos>\"]\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        output, prev_state = model.decoder(target_seq_tensor, prev_state)\n",
        "        top1 = output.argmax(1).view(-1, 1)\n",
        "        idx = int(top1.cpu())\n",
        "\n",
        "        if idx == eos:\n",
        "            break\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target.get(idx, \"\")\n",
        "            if word:\n",
        "                output_sentence.append(word)\n",
        "\n",
        "        # re-alimentar el token predicho\n",
        "        target_seq_tensor = top1.to(device)\n",
        "\n",
        "    return \" \".join(output_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgVnQa7tzia0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Traducciones (modelo grande) ===\n",
            "--------------------------------------------------\n",
            "EN: How are you?\n",
            "ES: ¡qué estás\n",
            "--------------------------------------------------\n",
            "EN: My mother says hi.\n",
            "ES: mi no que en habitación\n",
            "--------------------------------------------------\n",
            "EN: I like to learn machine learning.\n",
            "ES: me a a gusta los de\n",
            "--------------------------------------------------\n",
            "EN: This restaurant is very good.\n",
            "ES: este es buena muy\n",
            "--------------------------------------------------\n",
            "EN: I will call you tomorrow.\n",
            "ES: te a mañana mañana\n",
            "\n",
            "=== Ejemplos del dataset ===\n",
            "--------------------------------------------------\n",
            "EN      : We haven't been called to the meeting yet.\n",
            "ES real : Todavía no nos han citado para la reunión. <eos>\n",
            "ES pred : no estado de el de que la de\n",
            "--------------------------------------------------\n",
            "EN      : She's my older sister.\n",
            "ES real : Ella es mi hermana mayor. <eos>\n",
            "ES pred : ella mi es de padre mi\n",
            "--------------------------------------------------\n",
            "EN      : Everyone needs to know this.\n",
            "ES real : Todos tienen que saber esto. <eos>\n",
            "ES pred : a a a les les la de le\n",
            "--------------------------------------------------\n",
            "EN      : Tom applied for a passport.\n",
            "ES real : Tom solicitó un pasaporte. <eos>\n",
            "ES pred : tom a a le una de por\n",
            "--------------------------------------------------\n",
            "EN      : The road is too narrow for cars.\n",
            "ES real : El camino es muy estrecho para los autos. <eos>\n",
            "ES pred : el es de que más que la\n"
          ]
        }
      ],
      "source": [
        "# Ejemplos manuales\n",
        "test_sentences = [\n",
        "    \"How are you?\",\n",
        "    \"My mother says hi.\",\n",
        "    \"I like to learn machine learning.\",\n",
        "    \"This restaurant is very good.\",\n",
        "    \"I will call you tomorrow.\"\n",
        "]\n",
        "\n",
        "print(\"=== Traducciones===\")\n",
        "for s in test_sentences:\n",
        "    print(\"-\" * 50)\n",
        "    print(\"EN:\", s)\n",
        "    print(\"ES:\", translate_sentence(model_mid, s))\n",
        "\n",
        "# Ejemplos tomados del dataset (para comparar con la referencia)\n",
        "print(\"\\n=== Ejemplos del dataset ===\")\n",
        "for _ in range(5):\n",
        "    i = np.random.randint(len(input_sentences))\n",
        "    src = input_sentences[i]\n",
        "    tgt = output_sentences[i]\n",
        "    pred = translate_sentence(model_mid, src)\n",
        "    print(\"-\" * 50)\n",
        "    print(\"EN      :\", src)\n",
        "    print(\"ES real :\", tgt)\n",
        "    print(\"ES pred :\", pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estos ejemplos nos dan una idea cualitativa de cómo traduce el modelo.  Las oraciones cortas y simples suelen salir mejor, mientras que las más largas o con estructuras raras muestran más errores.  Esto indica que el modelo funciona como una prueba de concepto básica y que podría mejorar con más datos, un tamaño de estado oculto mayor, mecanismos de atención o más épocas de entrenamiento.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "6c - traductor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
